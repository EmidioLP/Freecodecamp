{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "authorship_tag": "ABX9TyMfRo+6yY7apyQE3QEl1El9",
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    },
    "accelerator": "GPU"
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/EmidioLP/Freecodecamp/blob/main/Notebooks/Machine%20Learning%20with%20Python/RNN_Generator.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "Esse notebook é baseado nas aulas disponibilizadas em: https://www.freecodecamp.org/portuguese/learn/machine-learning-with-python/"
      ],
      "metadata": {
        "id": "-0j_bFpU0Rfy"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "Esse notebook é baseado no seguinte guia disponibilizado na documentação do Tensorflow: https://www.tensorflow.org/tutorials/text/text_generator"
      ],
      "metadata": {
        "id": "kzftRv2z0bLs"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "#Imports e Setup"
      ],
      "metadata": {
        "id": "b1gUd0tD0lgs"
      }
    },
    {
      "cell_type": "code",
      "execution_count": 29,
      "metadata": {
        "id": "acgft63w0I-_"
      },
      "outputs": [],
      "source": [
        "from keras.preprocessing import sequence\n",
        "import keras\n",
        "import tensorflow as tf\n",
        "import os\n",
        "import numpy as np"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Dataset"
      ],
      "metadata": {
        "id": "BP8hkV9V0tu0"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "path_to_file = tf.keras.utils.get_file('shakespeare.txt', 'https://storage.googleapis.com/download.tensorflow.org/data/shakespeare.txt')"
      ],
      "metadata": {
        "id": "99TI01cb02ag"
      },
      "execution_count": 30,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Loading dos dados"
      ],
      "metadata": {
        "id": "Mvngc9Uh1Qaz"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "#Lê e depois decodifica para o formato py2\n",
        "text = open(path_to_file, 'rb').read().decode(encoding='utf-8')\n",
        "\n",
        "# \"Lenght of text\" é o número de caracteres contidos nele\n",
        "print('Lenght of text: {} characters'.format(len(text)))"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "yTSYRiKg1qzx",
        "outputId": "71f53f86-6fc3-4262-ee70-75e8a5d52dec"
      },
      "execution_count": 31,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Lenght of text: 1115394 characters\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "#Os primeiros 250 caracteres no texto\n",
        "print(text[:250])"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "tK5XjsNt2AVO",
        "outputId": "712e6268-92c3-441b-cd78-11f84e4bfd7a"
      },
      "execution_count": 32,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "First Citizen:\n",
            "Before we proceed any further, hear me speak.\n",
            "\n",
            "All:\n",
            "Speak, speak.\n",
            "\n",
            "First Citizen:\n",
            "You are all resolved rather to die than to famish?\n",
            "\n",
            "All:\n",
            "Resolved. resolved.\n",
            "\n",
            "First Citizen:\n",
            "First, you know Caius Marcius is chief enemy to the people.\n",
            "\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Codificando\n",
        "\n",
        "Como o texto não está codificado em números (que é como o modelo de IA precisa receber para entendê-lo), precisa-se fazer isso manualmente."
      ],
      "metadata": {
        "id": "N8QEsCL82IDU"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "vocab = sorted(set(text))\n",
        "# Mapeando caracteres únicos em indices\n",
        "char2idx = {u:i for i, u in enumerate(vocab)}\n",
        "idx2char = np.array(vocab)\n",
        "\n",
        "def text_to_int(text):\n",
        "  return np.array([char2idx[c] for c in text])\n",
        "\n",
        "text_as_int = text_to_int(text)"
      ],
      "metadata": {
        "id": "zIVWkorj2Rlk"
      },
      "execution_count": 33,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "print(\"Texto: \", text[:13])\n",
        "print(\"Codificado: \", text_to_int(text[:13]))"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "XgiufkcT23Kn",
        "outputId": "f00b3997-1466-4e47-e8d5-038451c06318"
      },
      "execution_count": 34,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Texto:  First Citizen\n",
            "Codificado:  [18 47 56 57 58  1 15 47 58 47 64 43 52]\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "Agora precisamos fazer o processo reverso."
      ],
      "metadata": {
        "id": "yHcL0QAA3Zs1"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "def int_to_text(ints):\n",
        "  try:\n",
        "    ints = ints.numpy()\n",
        "  except:\n",
        "    pass\n",
        "  return ''.join(idx2char[ints])\n",
        "\n",
        "print(int_to_text(text_as_int[:13]))"
      ],
      "metadata": {
        "id": "hi2SZQQS3bug",
        "outputId": "432db403-2775-4066-cfe8-7c3750caaad0",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "execution_count": 35,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "First Citizen\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Exemplos de treinamento"
      ],
      "metadata": {
        "id": "9iLR3-od4IVm"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "seq_lenght = 100\n",
        "examples_per_epoch = len(text)//(seq_lenght+1)\n",
        "\n",
        "char_dataset = tf.data.Dataset.from_tensor_slices(text_as_int)"
      ],
      "metadata": {
        "id": "QhdE2J4G4Koz"
      },
      "execution_count": 36,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "sequences = char_dataset.batch(seq_lenght+1, drop_remainder=True)"
      ],
      "metadata": {
        "id": "Sf5Oxy3O4VOO"
      },
      "execution_count": 37,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "def split_input_target(chunk):\n",
        "  input_text = chunk[:-1]\n",
        "  target_text = chunk[1:]\n",
        "  return input_text, target_text\n",
        "\n",
        "dataset = sequences.map(split_input_target)"
      ],
      "metadata": {
        "id": "21KXwiWc4fJA"
      },
      "execution_count": 38,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "for x, y in dataset.take(2):\n",
        "  print(\"\\n\\nEXEMPLO\\n\")\n",
        "  print(\"ENTRADA\")\n",
        "  print(int_to_text(x))\n",
        "  print(\"\\nSAIDA\")\n",
        "  print(int_to_text(y))"
      ],
      "metadata": {
        "id": "OKzZkPoR41o2",
        "outputId": "5427ab74-ca90-489b-c245-ee0fca2a9298",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "execution_count": 39,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "\n",
            "EXEMPLO\n",
            "\n",
            "ENTRADA\n",
            "First Citizen:\n",
            "Before we proceed any further, hear me speak.\n",
            "\n",
            "All:\n",
            "Speak, speak.\n",
            "\n",
            "First Citizen:\n",
            "You\n",
            "\n",
            "SAIDA\n",
            "irst Citizen:\n",
            "Before we proceed any further, hear me speak.\n",
            "\n",
            "All:\n",
            "Speak, speak.\n",
            "\n",
            "First Citizen:\n",
            "You \n",
            "\n",
            "\n",
            "EXEMPLO\n",
            "\n",
            "ENTRADA\n",
            "are all resolved rather to die than to famish?\n",
            "\n",
            "All:\n",
            "Resolved. resolved.\n",
            "\n",
            "First Citizen:\n",
            "First, you \n",
            "\n",
            "SAIDA\n",
            "re all resolved rather to die than to famish?\n",
            "\n",
            "All:\n",
            "Resolved. resolved.\n",
            "\n",
            "First Citizen:\n",
            "First, you k\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "BATCH_SIZE = 64\n",
        "VOCAB_SIZE = len(vocab)\n",
        "EMBEDDING_DIM = 256\n",
        "RNN_UNITS = 1024\n",
        "\n",
        "BUFFER_SIZE = 10000\n",
        "\n",
        "data = dataset.shuffle(BUFFER_SIZE).batch(BATCH_SIZE, drop_remainder=True)"
      ],
      "metadata": {
        "id": "MWsliPV95gdk"
      },
      "execution_count": 40,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Criando o modelo"
      ],
      "metadata": {
        "id": "T_DOgOZt52Hw"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "def build_model (vocab_size, embedding_dim, rnn_units, batch_size):\n",
        "  model = tf.keras.Sequential([\n",
        "      tf.keras.layers.Embedding(vocab_size, embedding_dim,\n",
        "                                batch_input_shape=[batch_size, None]),\n",
        "      tf.keras.layers.LSTM(rnn_units,\n",
        "                           return_sequences=True,\n",
        "                           stateful=True,\n",
        "                           recurrent_initializer='glorot_uniform'),\n",
        "      tf.keras.layers.Dense(vocab_size)\n",
        "  ])\n",
        "  return model\n",
        "\n",
        "model = build_model(VOCAB_SIZE, EMBEDDING_DIM, RNN_UNITS, BATCH_SIZE)\n",
        "model.summary()"
      ],
      "metadata": {
        "id": "gNhfESXX53Va",
        "outputId": "0e5c6e73-88dc-4333-9f30-633199ed2b22",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "execution_count": 41,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Model: \"sequential_1\"\n",
            "_________________________________________________________________\n",
            " Layer (type)                Output Shape              Param #   \n",
            "=================================================================\n",
            " embedding_1 (Embedding)     (64, None, 256)           16640     \n",
            "                                                                 \n",
            " lstm_1 (LSTM)               (64, None, 1024)          5246976   \n",
            "                                                                 \n",
            " dense_1 (Dense)             (64, None, 65)            66625     \n",
            "                                                                 \n",
            "=================================================================\n",
            "Total params: 5,330,241\n",
            "Trainable params: 5,330,241\n",
            "Non-trainable params: 0\n",
            "_________________________________________________________________\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Função de perca"
      ],
      "metadata": {
        "id": "_IV2xBX59jnb"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "for input_example_batch, target_example_batch in data.take(1):\n",
        "  example_batch_predictions = model(input_example_batch)\n",
        "  print(example_batch_predictions.shape, \"# (batch_size, sequence_lenght, vocab_size)\")"
      ],
      "metadata": {
        "id": "0rxZMf9v9lzT",
        "outputId": "177df6ab-7609-42fb-afa2-00be50ebd18b",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "execution_count": 42,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "(64, 100, 65) # (batch_size, sequence_lenght, vocab_size)\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "print(len(example_batch_predictions))\n",
        "print(example_batch_predictions)"
      ],
      "metadata": {
        "id": "RobWbfEf--W3",
        "outputId": "6767a38e-ad1b-4ac1-9c09-c13d44ffc7e1",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "execution_count": 43,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "64\n",
            "tf.Tensor(\n",
            "[[[-6.05892739e-04 -3.37977847e-03 -3.90926888e-03 ...  8.45648465e-04\n",
            "   -8.91830027e-03 -4.83177463e-03]\n",
            "  [ 5.10096899e-04 -2.40950333e-03 -8.15306511e-03 ... -1.41341193e-03\n",
            "   -3.59776616e-03 -6.67714281e-03]\n",
            "  [-4.77349525e-03 -2.94561265e-04 -1.00216772e-02 ... -5.39078936e-03\n",
            "   -3.14118853e-03 -3.71610979e-03]\n",
            "  ...\n",
            "  [-5.74917858e-03 -7.53174117e-03 -1.00325765e-02 ... -6.27444265e-03\n",
            "   -1.62619096e-03  4.76791849e-03]\n",
            "  [-4.45933128e-03 -4.96851932e-03 -5.12435474e-03 ... -2.61492771e-03\n",
            "   -1.22301513e-03  4.84899245e-03]\n",
            "  [-4.32439800e-03 -6.97122980e-03 -6.97569409e-03 ... -1.12863490e-03\n",
            "   -9.89405345e-03 -1.56578771e-03]]\n",
            "\n",
            " [[-2.35223700e-03  2.36068107e-03 -1.48341828e-03 ...  1.29843224e-03\n",
            "    3.83960200e-04 -1.91300781e-03]\n",
            "  [-2.41667207e-04  8.57054256e-04 -5.26400656e-03 ... -1.76611531e-03\n",
            "    3.31099238e-03 -4.37120069e-03]\n",
            "  [-2.18999432e-03  1.60882063e-03 -4.81852237e-03 ...  3.13408091e-05\n",
            "    2.58739712e-03 -4.95364983e-03]\n",
            "  ...\n",
            "  [ 8.93834420e-03 -8.73739307e-04 -2.49262713e-03 ... -5.03821298e-03\n",
            "   -1.26517611e-04  2.26230570e-03]\n",
            "  [ 1.13180317e-02  5.49769844e-04  5.92626457e-04 ...  1.39241479e-03\n",
            "   -7.24494085e-03 -9.10214148e-05]\n",
            "  [ 4.94160224e-03  2.84204283e-03  8.03032890e-05 ...  1.34462351e-03\n",
            "   -6.58683153e-03 -1.33344019e-03]]\n",
            "\n",
            " [[-4.98632994e-03  2.28844513e-03 -3.68842715e-03 ... -4.92640864e-03\n",
            "   -3.91130423e-04  1.01016939e-03]\n",
            "  [-7.06296065e-04 -1.01132342e-03  3.91605403e-03 ... -7.00231921e-03\n",
            "    5.66038862e-03  5.03331330e-03]\n",
            "  [ 9.76354931e-04 -3.83548148e-04 -1.66227692e-03 ... -8.89750198e-03\n",
            "    6.41106209e-03  6.34087832e-04]\n",
            "  ...\n",
            "  [-3.43481358e-03 -1.22383609e-02 -1.16025424e-02 ...  8.04237463e-03\n",
            "   -4.81748348e-03  3.06703034e-03]\n",
            "  [ 1.92614854e-03 -9.26285610e-03 -7.74444500e-03 ...  5.92682511e-03\n",
            "   -1.07998718e-02  4.39664023e-03]\n",
            "  [ 6.45267405e-03 -3.42605123e-03 -5.36179356e-03 ...  7.42818927e-03\n",
            "   -1.54278316e-02  6.14837627e-05]]\n",
            "\n",
            " ...\n",
            "\n",
            " [[ 3.17606376e-03 -3.34146339e-03  6.83643622e-03 ... -2.54947226e-03\n",
            "    6.35128608e-03  4.17215098e-03]\n",
            "  [ 7.94630218e-03 -1.10660889e-03  6.53981837e-03 ...  2.88642035e-03\n",
            "   -1.50513439e-03  1.62452925e-03]\n",
            "  [ 3.28757754e-03  1.77416950e-03  3.67467664e-03 ...  2.39878776e-03\n",
            "   -1.49724714e-03  3.10057774e-04]\n",
            "  ...\n",
            "  [ 7.45008281e-03 -3.21348896e-04 -8.91274586e-03 ... -6.77681481e-03\n",
            "   -1.04491729e-02 -8.37553060e-04]\n",
            "  [ 5.34101296e-03 -4.94830310e-05 -5.66617632e-03 ... -1.10287415e-02\n",
            "   -1.23984832e-02 -1.24770158e-03]\n",
            "  [ 2.22763419e-03 -7.07322499e-03 -4.42316383e-03 ... -1.04518197e-02\n",
            "   -1.18138837e-02 -1.57085049e-03]]\n",
            "\n",
            " [[ 4.01090505e-03 -1.53096789e-03 -4.56755515e-03 ...  2.63766502e-03\n",
            "    4.41380951e-04 -2.08948995e-03]\n",
            "  [ 5.08493558e-03 -1.56142097e-03 -2.80909636e-03 ... -2.46779947e-03\n",
            "    1.04744534e-03 -1.17905037e-02]\n",
            "  [ 5.23026427e-03 -2.55095377e-03 -2.10043415e-03 ... -6.13400666e-03\n",
            "    1.86168880e-03 -1.89728010e-02]\n",
            "  ...\n",
            "  [ 9.22470074e-03  7.16138165e-04  7.76652526e-03 ...  2.18347297e-03\n",
            "   -7.12316111e-03  2.85646133e-03]\n",
            "  [ 3.10812634e-03  3.93637689e-03  4.92885383e-03 ...  1.32880546e-03\n",
            "   -6.49902225e-03  1.71721634e-03]\n",
            "  [-2.70258635e-04  4.68755607e-04  2.48032156e-03 ... -4.06595739e-03\n",
            "   -5.04633784e-03  5.39615238e-03]]\n",
            "\n",
            " [[-3.35608143e-04  5.54856495e-04  7.59230927e-04 ... -5.74763818e-03\n",
            "   -2.88176676e-03 -8.74895835e-04]\n",
            "  [-2.04711291e-03 -6.53806329e-03  1.37946510e-04 ... -6.38455339e-03\n",
            "   -3.18827527e-03 -1.44032296e-03]\n",
            "  [-3.38508282e-03 -1.58737844e-03 -1.49383908e-03 ... -2.77889846e-03\n",
            "   -3.08651710e-03 -2.59386818e-03]\n",
            "  ...\n",
            "  [ 1.10030035e-03 -4.85235685e-03 -3.42736416e-03 ...  1.97588489e-03\n",
            "   -3.28627601e-03 -1.53386430e-03]\n",
            "  [ 3.52706807e-03 -6.29332382e-03  4.03007306e-03 ... -4.49281855e-04\n",
            "    4.38347505e-03  2.73795845e-03]\n",
            "  [ 3.26823536e-03 -8.12610425e-03  5.34327002e-04 ... -1.74905278e-03\n",
            "    6.68038847e-04  1.44726839e-02]]], shape=(64, 100, 65), dtype=float32)\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "pred = example_batch_predictions[0]\n",
        "print(len(pred))\n",
        "print(pred)"
      ],
      "metadata": {
        "id": "QvdHphD6_C1c",
        "outputId": "300dc7cb-4425-4314-8f54-e5b6368a2bb8",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "execution_count": 44,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "100\n",
            "tf.Tensor(\n",
            "[[-0.00060589 -0.00337978 -0.00390927 ...  0.00084565 -0.0089183\n",
            "  -0.00483177]\n",
            " [ 0.0005101  -0.0024095  -0.00815307 ... -0.00141341 -0.00359777\n",
            "  -0.00667714]\n",
            " [-0.0047735  -0.00029456 -0.01002168 ... -0.00539079 -0.00314119\n",
            "  -0.00371611]\n",
            " ...\n",
            " [-0.00574918 -0.00753174 -0.01003258 ... -0.00627444 -0.00162619\n",
            "   0.00476792]\n",
            " [-0.00445933 -0.00496852 -0.00512435 ... -0.00261493 -0.00122302\n",
            "   0.00484899]\n",
            " [-0.0043244  -0.00697123 -0.00697569 ... -0.00112863 -0.00989405\n",
            "  -0.00156579]], shape=(100, 65), dtype=float32)\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "time_pred = pred[0]\n",
        "print(len(time_pred))\n",
        "print(time_pred)"
      ],
      "metadata": {
        "id": "NuELGWp0_eqV",
        "outputId": "4193d63d-3b40-47f2-96f8-cd85ea1e9efe",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "execution_count": 45,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "65\n",
            "tf.Tensor(\n",
            "[-0.00060589 -0.00337978 -0.00390927 -0.00226954  0.00746787  0.00479183\n",
            " -0.00399925 -0.00051312 -0.0009087  -0.00073041  0.00209333  0.00452559\n",
            " -0.00021021 -0.00367695 -0.00156662  0.00558799  0.00092511  0.00535244\n",
            " -0.00179569 -0.00558419 -0.00215855  0.00475921  0.0008378   0.00485588\n",
            "  0.00113676  0.00373671  0.00531295 -0.0023434   0.00197843  0.00052371\n",
            " -0.00287172 -0.00208545 -0.00698696  0.00303419  0.0046215   0.0059813\n",
            " -0.0031674  -0.00265574 -0.00802405  0.00397396 -0.00142589 -0.00099517\n",
            " -0.00369721 -0.00206712 -0.00384627  0.00241514  0.00144103  0.00172034\n",
            " -0.00044787 -0.00601247 -0.0050223  -0.00041257  0.00138143  0.00254072\n",
            "  0.00084804  0.0020211  -0.00436445  0.00067724 -0.00416494  0.00259625\n",
            " -0.0021704   0.00265137  0.00084565 -0.0089183  -0.00483177], shape=(65,), dtype=float32)\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "sampled_indices = tf.random.categorical(pred, num_samples=1)\n",
        "\n",
        "sampled_indices = np.reshape(sampled_indices, (1, -1))[0]\n",
        "predicted_chars = int_to_text(sampled_indices)\n",
        "\n",
        "predicted_chars"
      ],
      "metadata": {
        "id": "ybmFTKCLATQe",
        "outputId": "f7e80112-911e-4ebb-95d9-622bed3d1a88",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 35
        }
      },
      "execution_count": 46,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "\"FkJyv&R;diWX,dM,tST$d.oAO&V'-k;h kqLiMBoW:tW:Ak&v;i?wOy,UAHOzPjrZS,PGgmgFu:t3Ce3h?Izcl;h'loVvbnSyF$i\""
            ],
            "application/vnd.google.colaboratory.intrinsic+json": {
              "type": "string"
            }
          },
          "metadata": {},
          "execution_count": 46
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "def loss(labels, logits):\n",
        "  return tf.keras.losses.sparse_categorical_crossentropy(labels, logits, from_logits=True)"
      ],
      "metadata": {
        "id": "EdsVoaFLAt78"
      },
      "execution_count": 47,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Compilando o modelo"
      ],
      "metadata": {
        "id": "JRPaN6J5A0mE"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "model.compile(optimizer='adam', loss=loss)"
      ],
      "metadata": {
        "id": "DLbiy0r6A288"
      },
      "execution_count": 64,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Craindo checkpoints"
      ],
      "metadata": {
        "id": "D11K9PdEBKDI"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "checkpoint_dir = './training_checkpoints'\n",
        "\n",
        "checkpoint_prefix = os.path.join(checkpoint_dir, \"ckpt_(epoch)\")\n",
        "\n",
        "checkpoint_callback=tf.keras.callbacks.ModelCheckpoint(\n",
        "    filepath=checkpoint_prefix,\n",
        "    save_weigths_only=True)"
      ],
      "metadata": {
        "id": "ZTACz_9QBMMb"
      },
      "execution_count": 62,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Conteúdos extras\n",
        "\n",
        "https://colah.github.io/posts/2015-08-Understanding-LSTMs/"
      ],
      "metadata": {
        "id": "5TvzukbVEvD5"
      }
    }
  ]
}